{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1667512605464,"user":{"displayName":"Robbe De Groeve","userId":"05059392042884882299"},"user_tz":-60},"id":"1Eh_cN6nrpKm","outputId":"ca479412-d073-4453-c70e-a6a4af654594"},"outputs":[{"name":"stdout","output_type":"stream","text":["env: CUDA_LAUNCH_BLOCKING=1\n"]}],"source":["%env CUDA_LAUNCH_BLOCKING=1"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14969,"status":"ok","timestamp":1667512620425,"user":{"displayName":"Robbe De Groeve","userId":"05059392042884882299"},"user_tz":-60},"id":"3pld4fqR-LTd","outputId":"8cc2069d-db54-4e9e-e998-a6de1bf59e43"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting wandb\n","  Downloading wandb-0.13.5-py2.py3-none-any.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n","Collecting shortuuid\u003e=0.5.0\n","  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n","Collecting docker-pycreds\u003e=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting sentry-sdk\u003e=1.0.0\n","  Downloading sentry_sdk-1.10.1-py2.py3-none-any.whl (166 kB)\n","\u001b[K     |████████████████████████████████| 166 kB 58.4 MB/s \n","\u001b[?25hRequirement already satisfied: psutil\u003e=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: Click!=8.0.0,\u003e=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n","Collecting GitPython\u003e=1.0.0\n","  Downloading GitPython-3.1.29-py3-none-any.whl (182 kB)\n","\u001b[K     |████████████████████████████████| 182 kB 55.7 MB/s \n","\u001b[?25hCollecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","Requirement already satisfied: six\u003e=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Requirement already satisfied: protobuf!=4.0.*,!=4.21.0,\u003c5,\u003e=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Collecting setproctitle\n","  Downloading setproctitle-1.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Requirement already satisfied: requests\u003c3,\u003e=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Requirement already satisfied: promise\u003c3,\u003e=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython\u003e=1.0.0-\u003ewandb) (4.1.1)\n","Collecting gitdb\u003c5,\u003e=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 918 kB/s \n","\u001b[?25hCollecting smmap\u003c6,\u003e=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.0.0-\u003ewandb) (3.0.4)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.0.0-\u003ewandb) (2022.9.24)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.0.0-\u003ewandb) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.0.0-\u003ewandb) (1.24.3)\n","Collecting sentry-sdk\u003e=1.0.0\n","  Downloading sentry_sdk-1.10.0-py2.py3-none-any.whl (166 kB)\n","\u001b[K     |████████████████████████████████| 166 kB 43.0 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.10-py2.py3-none-any.whl (162 kB)\n","\u001b[K     |████████████████████████████████| 162 kB 42.8 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.9-py2.py3-none-any.whl (162 kB)\n","\u001b[K     |████████████████████████████████| 162 kB 43.5 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.8-py2.py3-none-any.whl (158 kB)\n","\u001b[K     |████████████████████████████████| 158 kB 45.5 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.7-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 44.8 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.6-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 46.5 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.5-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 44.2 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.4-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 45.5 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.3-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 44.6 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.2-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 10.9 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.1-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 32.2 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.0-py2.py3-none-any.whl (156 kB)\n","\u001b[K     |████████████████████████████████| 156 kB 44.6 MB/s \n","\u001b[?25hBuilding wheels for collected packages: pathtools\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=e9f00265c9147ac8660baa38baf21b6b6bf15f9425f9f93711fdc23da8983ea1\n","  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n","Successfully built pathtools\n","Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n","Successfully installed GitPython-3.1.29 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.9.0 setproctitle-1.3.2 shortuuid-1.0.9 smmap-5.0.0 wandb-0.13.5\n"]}],"source":["# Installs\n","!pip install wandb"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20481,"status":"ok","timestamp":1667512640901,"user":{"displayName":"Robbe De Groeve","userId":"05059392042884882299"},"user_tz":-60},"id":"mcRCN3WQ999F","outputId":"740008d4-6605-4fed-b03c-c976011c87dd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["# Google drive setup\n","from google.colab import drive\n","from os.path import join\n","from os import chdir\n","\n","MOUNT_PATH_DRIVE = '/content/drive'\n","BASE_PATH = join(\n","      MOUNT_PATH_DRIVE, \n","      \"MyDrive/School/2022-2023/Sem1/ai_indistrial_perspectives/barco/barco_skin_lesion_classification\"\n","  )\n","CODE_PATH = join(BASE_PATH, 'src/')\n","\n","# Mount the google drive\n","drive.mount(MOUNT_PATH_DRIVE)\n","\n","# Set the base path of the project\n","chdir(CODE_PATH)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":10659,"status":"ok","timestamp":1667512651553,"user":{"displayName":"Robbe De Groeve","userId":"05059392042884882299"},"user_tz":-60},"id":"m9XYx47j1usN"},"outputs":[],"source":["# Imports\n","# Utils\n","import matplotlib as plt\n","import numpy as np\n","import wandb\n","import sys\n","import importlib\n","from PIL import Image, ImageFile\n","ImageFile.LOAD_TRUNCATED_IMAGES = True\n","import datetime\n","\n","\n","# DL libraries\n","import torch\n","import torch.optim as optim\n","from torch import nn\n","from torch.utils.data import DataLoader\n","\n","# User libraries\n","from datasets.segmentationdataset import SegmentationDataset\n","from models.unet_model import UNet\n","from trainers.segmentation_model_trainer import train_segmentation_model\n","from validators.segmentation_model_validator import validate_segmentation_model\n","from util import config"]},{"cell_type":"markdown","metadata":{"id":"okJ4faCb1usQ"},"source":["# Data"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":11066,"status":"ok","timestamp":1667512662598,"user":{"displayName":"Robbe De Groeve","userId":"05059392042884882299"},"user_tz":-60},"id":"tvCQM1nG1usR"},"outputs":[],"source":["# Get the data\n","train_segmentation_dataset = SegmentationDataset(\n","    join(BASE_PATH, config.SEGMENTATION_DATA_PATH_TRAIN_FEATURES),\n","    join(BASE_PATH, config.SEGMENTATION_DATA_PATH_TRAIN_LABELS),\n","    config.SEGMENTATION_TRAIN_TRANSFORMATIONS_BOTH\n","    )\n","\n","test_segmentation_dataset = SegmentationDataset(\n","    join(BASE_PATH, config.SEGMENTATION_DATA_PATH_TEST_FEATURES),\n","    join(BASE_PATH, config.SEGMENTATION_DATA_PATH_TEST_LABELS),\n","    config.SEGMENTATION_TEST_TRANSFORMATIONS_BOTH\n","    )\n","\n","# Place the datasets in dataloaders\n","train_segmentation_dataloader = DataLoader(train_segmentation_dataset, batch_size=config.SEGMENTATION_BATCH_SIZE)\n","test_segmentation_dataloader = DataLoader(test_segmentation_dataset, batch_size=1)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"VtWZdx5x1usS"},"source":["# Setup"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":256},"executionInfo":{"elapsed":10642,"status":"ok","timestamp":1667512673233,"user":{"displayName":"Robbe De Groeve","userId":"05059392042884882299"},"user_tz":-60},"id":"P8YQibBf1usS","outputId":"507ea8cb-13a9-464d-e266-6a2c043893c1"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/cuda/amp/grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n","  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n","ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"]},{"data":{"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) =\u003e {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() =\u003e {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() =\u003e reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data =\u003e {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "],"text/plain":["\u003cIPython.core.display.Javascript object\u003e"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrobberdg\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["Tracking run with wandb version 0.13.5"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in \u003ccode\u003e/content/drive/MyDrive/School/2022-2023/Sem1/ai_indistrial_perspectives/barco/barco_skin_lesion_classification/src/wandb/run-20221103_215749-2lskzu7u\u003c/code\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run \u003cstrong\u003e\u003ca href=\"https://wandb.ai/robberdg/test-project/runs/2lskzu7u\" target=\"_blank\"\u003eexperiment_2022-11-03 21:57:48.957059\u003c/a\u003e\u003c/strong\u003e to \u003ca href=\"https://wandb.ai/robberdg/test-project\" target=\"_blank\"\u003eWeights \u0026 Biases\u003c/a\u003e (\u003ca href=\"https://wandb.me/run\" target=\"_blank\"\u003edocs\u003c/a\u003e)\u003cbr/\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cbutton onClick=\"this.nextSibling.style.display='block';this.style.display='none';\"\u003eDisplay W\u0026B run\u003c/button\u003e\u003ciframe src=\"https://wandb.ai/robberdg/test-project/runs/2lskzu7u?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"\u003e\u003c/iframe\u003e"],"text/plain":["\u003cwandb.sdk.wandb_run.Run at 0x7f50a344a050\u003e"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# Get the model\n","model = UNet(n_channels=3, n_classes=1, bilinear=False)\n","model.to(config.DEVICE)\n","\n","# Set the optimizer\n","optimizer = optim.Adam(model.parameters(), lr=config.SEGMENTATION_LR)\n","\n","# Set the loss fn\n","criteria = nn.BCEWithLogitsLoss()\n","\n","# Set the gradient scaler\n","grad_scaler = torch.cuda.amp.grad_scaler.GradScaler()\n","\n","\n","# Setup weights and biasses\n","wandb.login()\n","\n","# Start wandb\n","wandb.init(\n","    settings=wandb.Settings(start_method=\"fork\"),\n","    project=\"test-project\", \n","    name=f\"experiment_{datetime.datetime.now()}\", \n","    config={\n","        \"learning_rate\": config.SEGMENTATION_LR,\n","        \"batch_size\": config.SEGMENTATION_BATCH_SIZE,\n","        \"epochs\": config.SEGMENTATION_EPOCHS,\n","    }\n",")"]},{"cell_type":"markdown","metadata":{"id":"I7jFAKRb1usT"},"source":["# Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"FfESHBB51usU"},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 1/312 [06:08\u003c31:51:38, 368.81s/it]\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-7-606188305816\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0mcriteria\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0mgrad_scaler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 15\u001b[0;31m       \u001b[0mtrain_segmentation_dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m   )\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/School/2022-2023/Sem1/ai_indistrial_perspectives/barco/barco_skin_lesion_classification/src/trainers/segmentation_model_trainer.py\u001b[0m in \u001b[0;36mtrain_segmentation_model\u001b[0;34m(model, optimizer, loss_fn, scaler, dataloader)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# Backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 34\u001b[0;31m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--\u003e 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Set the variables to keep track of the best model\n","best_validation_loss = 10000\n","best_model_state = model.state_dict()\n","\n","for epoch in range(config.SEGMENTATION_EPOCHS):\n","  # Set the model in training mode\n","  model.train()\n","\n","  # Train the model\n","  total_train_loss_this_epoch = train_segmentation_model(\n","      model,\n","      optimizer,\n","      criteria,\n","      grad_scaler,\n","      train_segmentation_dataloader\n","  )\n","  \n","  # Set the model in evaluation mode\n","  model.eval()\n","\n","  # Validate the model\n","  total_val_loss_this_epoch, sample_image_array = validate_segmentation_model(\n","      model,\n","      criteria,\n","      test_segmentation_dataloader,\n","      test_segmentation_dataset\n","  )\n","\n","  # Convert the image array to a real imag object\n","  sample_image_array = sample_image_array.cpu()\n","  sample_image = Image.fromarray(np.uint8(sample_image_array) , 'L')\n","\n","  # Calculate the loss values\n","  train_loss_this_epoch = total_train_loss_this_epoch/len(train_segmentation_dataloader.dataset)\n","  val_loss_this_epoch = total_val_loss_this_epoch/len(test_segmentation_dataloader.dataset)\n","\n","  # Log the train loss this epoch\n","  wandb.log({\n","      'train_loss': train_loss_this_epoch,\n","      'val_loss': val_loss_this_epoch,\n","      'sample_image': wandb.Image(sample_image)\n","  })\n","\n","  print(f'epoch: {epoch}, train_loss: {train_loss_this_epoch}, val_loss: {val_loss_this_epoch}')\n","\n","  # If this is the best performing model yet, save it\n","  if val_loss_this_epoch \u003c best_validation_loss:\n","    # Update the best value\n","    best_validation_loss = val_loss_this_epoch\n","\n","    # Update the best model\n","    best_model_state = model.state_dict()\n","\n","    # Save the best model\n","    checkpoint_path = join(\n","      BASE_PATH, \n","      config.SEGMENTATION_MODEL_CHECKPOINT_PATH, \n","      f'chechpoint_{datetime.datetime.now()}.pth'\n","    )\n","    torch.save(best_model_state, checkpoint_path)\n","\n","\n","# Mark the run as finished\n","wandb.finish()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"hxj64_t4o-g6"},"outputs":[],"source":["# Save the best model\n","checkpoint_path = join(\n","    BASE_PATH, \n","    config.SEGMENTATION_MODEL_CHECKPOINT_PATH, \n","    f'chechpoint_{datetime.datetime.now()}.pth'\n","  )\n","torch.save(best_model_state, checkpoint_path)\n"]}],"metadata":{"accelerator":"TPU","colab":{"collapsed_sections":[],"name":"","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.10.6 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat":4,"nbformat_minor":0}